{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex3q2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNugLMvc778o46sAofam4BZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamirmal/advanced_topics_in_learning/blob/master/ex3q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPcySKd-9td3",
        "outputId": "86b99fcd-672e-47d0-831f-5f770b075710"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "GDRIVE_PATH='/gdrive/MyDrive/Colab_TAU/ComputationalLearning/'\n",
        "\n",
        "!pip3 -qq install ipdb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "\u001b[K     |████████████████████████████████| 788kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 10.6MB/s \n",
            "\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.22.0 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg7a0QNy_C5q",
        "outputId": "4e1bcbc4-8577-4787-e0f8-8c4bb806d359"
      },
      "source": [
        "import numpy as np\n",
        "Xtrain = np.loadtxt(GDRIVE_PATH+'MNIST_train_images.csv', delimiter=',')\n",
        "Ytrain = np.loadtxt(GDRIVE_PATH+'MNIST_train_labels.csv', delimiter=',')\n",
        "Xtest = np.loadtxt(GDRIVE_PATH+'MNIST_test_images.csv', delimiter=',')\n",
        "Ytest = np.loadtxt(GDRIVE_PATH+'MNIST_test_labels.csv', delimiter=',')\n",
        "\n",
        "print(Xtrain.shape)\n",
        "print(Ytest)\n",
        "print(Ytest.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11696, 784)\n",
            "[-1. -1. -1. ... -1.  1. -1.]\n",
            "(1954,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEngI398FrDq"
      },
      "source": [
        "##\n",
        "## this is a vectorization attemp\n",
        "## the idea is to try all possible h in one go\n",
        "## for a fixed theta\n",
        "def vec_err_by_distribution(theta, p, S, dir):\n",
        "  Sx, Sy = S\n",
        "  assert len(Sx) == len(Sy)\n",
        "  assert len(p) == len(Sx)\n",
        "  assert len(Sx[0] == 784)\n",
        "  assert dir in [-1, 1]\n",
        "\n",
        "  # over entire sample\n",
        "  # at each possible pixel idx, check if its smaller than theta (1 or 0)\n",
        "  # example for a given example:\n",
        "  #  x = (0, 0, ... 100, 105, 105, .... 0, 0) // len(x)=784\n",
        "  #  h_of_x = (0 < theta, 0 < theta, ..., 100 < theta, 105 < theta, 105 < theta, ... , 0 < theta, 0 < theta)\n",
        "  #  h_of_x = (T, T, ... , F, F, F, ... , T, T)\n",
        "  # for all examples we wil get a matrix of T / F at each idx\n",
        "  # then apply 'weigth' of each example - by distribution p\n",
        "  bool_h_of_x = (Sx <= theta)\n",
        "  # given back in T or F - we ned to convert to -1 / 1\n",
        "  h_of_x = np.ones_like(bool_h_of_x) * -dir # init template array to '-1 * dir'\n",
        "  h_of_x[bool_h_of_x] = dir # where its true - set to dir\n",
        "  #print(h_of_x.shape)\n",
        "\n",
        "  # compare to Sy - need to convert vec of labels to matrix of labels\n",
        "  Sy_tile = np.tile(Sy, (len(Sx[0]),1))\n",
        "  Sy_tile = np.transpose(Sy_tile)\n",
        "  err = (Sy_tile != h_of_x)\n",
        "  err = err.astype(np.uint8)\n",
        "  #print(err.shape)\n",
        "\n",
        "  # our target is to find h that minimizes err by some distribution\n",
        "  # so first apply the distribution for all samples\n",
        "  p_tile = np.tile(p, (len(Sx[0]),1))\n",
        "  p_tile = np.transpose(p_tile)\n",
        "  #print(f\"p={p.shape}, p_tile={p_tile.shape}\")\n",
        "  weighted_err = err * p_tile\n",
        "\n",
        "  ## now after applying dist - we need to calc the error by sum\n",
        "  sum_weighted_err = np.sum(weighted_err, axis=0)\n",
        "  assert len(sum_weighted_err) == len(Sx[0])\n",
        "  #print(f\"sum_w_err={sum_weighted_err.shape}\")\n",
        "  \n",
        "  ## Look which idx gave lowest err\n",
        "  # find which pixel idx has 'best' err\n",
        "  best_h = np.argmin(sum_weighted_err)\n",
        "  #print(f\"best_h is at idx={best_h}, err={sum_weighted_err[best_h]}\")\n",
        "  h_of_x = h_of_x[:, best_h]\n",
        "  #print(f\"h_of_x={h_of_x}\")\n",
        "  return best_h, sum_weighted_err[best_h], h_of_x\n",
        "\n",
        "def Adaboost(S, T):\n",
        "  Sx, Sy = S\n",
        "\n",
        "  m = len(Sx)\n",
        "  p = np.ones(m) / m\n",
        "  H_T = []\n",
        "  for t in range(T):\n",
        "    EPSILON = 1E-5\n",
        "    if np.sum(p) > (1 + EPSILON) or np.sum(p) < (1 - EPSILON):\n",
        "      print(f\"sum(p)={np.sum(p)}\")\n",
        "      assert 0\n",
        "\n",
        "    #Find ht = arg minh∈H Px∼pt[h(x) != y].\n",
        "    ## lets analyze this ...\n",
        "    ## h(x) != y   ===> this is the error / loss\n",
        "    ## x ~ pt      ===> by some sample distribution\n",
        "    ## so for some h(theta,j), we need to calculate the err for each sample and the \"weigth\" it by the distribution vector p\n",
        "    ##\n",
        "    ## note - these nested loops over dir/theta can be paralleld with 'workers' in scikit-learn n_jobs (uses more cpu's)\n",
        "    best_h = {'idx': None, 'theta': None, 'dir': None, 'err': 1, 'h_of_x': None}\n",
        "    for dir in [-1, 1]:\n",
        "      for theta in range(256):\n",
        "        best_h_idx, err, h_of_x = vec_err_by_distribution(theta, p, S, dir)\n",
        "        if err < best_h['err']:\n",
        "          best_h['theta'] = theta\n",
        "          best_h['idx'] = best_h_idx\n",
        "          best_h['err'] = err\n",
        "          best_h['h_of_x'] = h_of_x\n",
        "          best_h['dir'] = dir\n",
        "    # end\n",
        "\n",
        "    e_t = best_h['err']\n",
        "    a_t = 0.5*np.log((1-e_t)/e_t)\n",
        "    best_h['a_t'] = a_t\n",
        "    H_T.append(best_h)\n",
        "    #update p\n",
        "    h_of_x = best_h['h_of_x']\n",
        "    h_of_x_aux = np.exp(h_of_x * Sy * -1.0 * a_t)\n",
        "    p_MUL_h_of_x_aux = p * h_of_x_aux\n",
        "    new_p = p_MUL_h_of_x_aux / np.sum(p_MUL_h_of_x_aux)\n",
        "    prev_p = p\n",
        "    p = new_p\n",
        "    if False:\n",
        "      print('*'*80)\n",
        "      print(f\"t={t}:best_h={best_h}, a_t={a_t}\")\n",
        "      print(f\"h_of_x={h_of_x.shape}, Sy={Sy.shape}\")\n",
        "      print(f\"h_of_x={h_of_x}, Sy={Sy}\")\n",
        "      print(f\"p={p}\")\n",
        "    else:\n",
        "      print(f\"t={t} done\")\n",
        "  # end\n",
        "  return H_T\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx5O6VsnWoja",
        "outputId": "3d88608b-ba0b-4b2c-b27f-5d6a1d0ccf9f"
      },
      "source": [
        "## training\n",
        "#H_T = Adaboost((Xtest, Ytest), 3)\n",
        "H_T = Adaboost((Xtrain, Ytrain), 30)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t=0 done\n",
            "t=1 done\n",
            "t=2 done\n",
            "t=3 done\n",
            "t=4 done\n",
            "t=5 done\n",
            "t=6 done\n",
            "t=7 done\n",
            "t=8 done\n",
            "t=9 done\n",
            "t=10 done\n",
            "t=11 done\n",
            "t=12 done\n",
            "t=13 done\n",
            "t=14 done\n",
            "t=15 done\n",
            "t=16 done\n",
            "t=17 done\n",
            "t=18 done\n",
            "t=19 done\n",
            "t=20 done\n",
            "t=21 done\n",
            "t=22 done\n",
            "t=23 done\n",
            "t=24 done\n",
            "t=25 done\n",
            "t=26 done\n",
            "t=27 done\n",
            "t=28 done\n",
            "t=29 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmp911JNAFDF",
        "outputId": "de308520-892d-4c6d-e691-4dcde88b30c1"
      },
      "source": [
        "print(H_T)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'idx': 406, 'theta': 1, 'dir': -1, 'err': 0.03505471956224338, 'h_of_x': array([-1,  1, -1, ...,  1,  1,  1]), 'a_t': 1.6575805694153678}, {'idx': 455, 'theta': 15, 'dir': 1, 'err': 0.11432510816336398, 'h_of_x': array([-1,  1, -1, ...,  1,  1,  1]), 'a_t': 1.0236518641911103}, {'idx': 408, 'theta': 0, 'dir': -1, 'err': 0.20261775170347643, 'h_of_x': array([-1,  1, -1, ...,  1,  1,  1]), 'a_t': 0.6850064826390513}, {'idx': 522, 'theta': 30, 'dir': 1, 'err': 0.22357657882910661, 'h_of_x': array([-1,  1, -1, ...,  1,  1,  1]), 'a_t': 0.6224720136307526}, {'idx': 461, 'theta': 0, 'dir': -1, 'err': 0.24585926069139474, 'h_of_x': array([-1,  1, -1, ...,  1,  1,  1]), 'a_t': 0.5604098731469328}, {'idx': 453, 'theta': 127, 'dir': 1, 'err': 0.23998511194360653, 'h_of_x': array([ 1,  1, -1, ...,  1,  1,  1]), 'a_t': 0.5763805673934332}, {'idx': 351, 'theta': 147, 'dir': -1, 'err': 0.26529267706939386, 'h_of_x': array([-1,  1,  1, ..., -1, -1, -1]), 'a_t': 0.5093192807526573}, {'idx': 266, 'theta': 227, 'dir': 1, 'err': 0.29882320959005804, 'h_of_x': array([ 1,  1, -1, ...,  1,  1,  1]), 'a_t': 0.4264539632191672}, {'idx': 462, 'theta': 67, 'dir': -1, 'err': 0.27651307530945735, 'h_of_x': array([-1,  1, -1, ...,  1, -1, -1]), 'a_t': 0.48091218256077695}, {'idx': 548, 'theta': 220, 'dir': 1, 'err': 0.2892297742617304, 'h_of_x': array([-1,  1,  1, ...,  1, -1,  1]), 'a_t': 0.44956388407873465}, {'idx': 541, 'theta': 61, 'dir': 1, 'err': 0.30885712855215225, 'h_of_x': array([ 1, -1,  1, ..., -1, -1, -1]), 'a_t': 0.4027338799921447}, {'idx': 414, 'theta': 2, 'dir': 1, 'err': 0.3279047179669881, 'h_of_x': array([-1,  1, -1, ...,  1,  1,  1]), 'a_t': 0.35883852351608736}, {'idx': 351, 'theta': 41, 'dir': -1, 'err': 0.31186951812593783, 'h_of_x': array([-1,  1,  1, ..., -1,  1, -1]), 'a_t': 0.39569679231901767}, {'idx': 269, 'theta': 32, 'dir': 1, 'err': 0.31468376758248395, 'h_of_x': array([-1, -1, -1, ...,  1,  1,  1]), 'a_t': 0.38915608138298824}, {'idx': 490, 'theta': 3, 'dir': -1, 'err': 0.34042482847461814, 'h_of_x': array([-1,  1, -1, ...,  1, -1, -1]), 'a_t': 0.33070080755448233}, {'idx': 571, 'theta': 222, 'dir': 1, 'err': 0.33612849703672243, 'h_of_x': array([ 1,  1,  1, ...,  1,  1, -1]), 'a_t': 0.34029754630185327}, {'idx': 177, 'theta': 0, 'dir': -1, 'err': 0.33872500842394093, 'h_of_x': array([-1, -1, -1, ..., -1, -1, -1]), 'a_t': 0.33449059165010525}, {'idx': 409, 'theta': 0, 'dir': -1, 'err': 0.34696765459955997, 'h_of_x': array([-1,  1, -1, ...,  1, -1,  1]), 'a_t': 0.31619755019812146}, {'idx': 327, 'theta': 45, 'dir': 1, 'err': 0.36562729452298076, 'h_of_x': array([ 1, -1, -1, ..., -1, -1, -1]), 'a_t': 0.2755110758283669}, {'idx': 434, 'theta': 67, 'dir': -1, 'err': 0.3605894351642775, 'h_of_x': array([-1,  1, -1, ...,  1,  1,  1]), 'a_t': 0.28640337356569384}, {'idx': 272, 'theta': 243, 'dir': 1, 'err': 0.33990441121737625, 'h_of_x': array([-1,  1, -1, ...,  1, -1,  1]), 'a_t': 0.3318601107092811}, {'idx': 350, 'theta': 196, 'dir': -1, 'err': 0.3591457554834949, 'h_of_x': array([-1, -1, -1, ..., -1, -1, -1]), 'a_t': 0.28953686659561}, {'idx': 495, 'theta': 8, 'dir': 1, 'err': 0.3483804167604268, 'h_of_x': array([-1,  1, -1, ...,  1,  1,  1]), 'a_t': 0.31308294801406494}, {'idx': 207, 'theta': 5, 'dir': -1, 'err': 0.37260978621388974, 'h_of_x': array([ 1,  1, -1, ..., -1,  1, -1]), 'a_t': 0.2605184875511987}, {'idx': 403, 'theta': 24, 'dir': -1, 'err': 0.36466684064879795, 'h_of_x': array([-1,  1, -1, ...,  1, -1,  1]), 'a_t': 0.2775826751446793}, {'idx': 461, 'theta': 149, 'dir': -1, 'err': 0.37274054851707544, 'h_of_x': array([-1,  1, -1, ...,  1, -1,  1]), 'a_t': 0.26023882801403203}, {'idx': 455, 'theta': 238, 'dir': 1, 'err': 0.3585215672165614, 'h_of_x': array([-1,  1, -1, ...,  1,  1,  1]), 'a_t': 0.2908933728407122}, {'idx': 575, 'theta': 2, 'dir': 1, 'err': 0.37453174663695443, 'h_of_x': array([-1, -1, -1, ..., -1, -1,  1]), 'a_t': 0.2564120022562018}, {'idx': 379, 'theta': 144, 'dir': -1, 'err': 0.39194832981577893, 'h_of_x': array([-1,  1, -1, ..., -1,  1, -1]), 'a_t': 0.21956492140138723}, {'idx': 440, 'theta': 207, 'dir': 1, 'err': 0.3697027047076291, 'h_of_x': array([-1,  1,  1, ...,  1,  1,  1]), 'a_t': 0.2667462117491244}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvozRexoWrZ_",
        "outputId": "346f8830-c6ee-4f34-b8eb-aa5ae884435f"
      },
      "source": [
        "## evaluation\n",
        "def predict_with_h(h_dict, X):\n",
        "  X_in_idx = X[:, h_dict['idx']]\n",
        "  bool_h_of_x = (X_in_idx <= h_dict['theta'])\n",
        "  h_of_x = np.ones_like(bool_h_of_x) * -h_dict['dir']\n",
        "  h_of_x[bool_h_of_x] = h_dict['dir']\n",
        "  #print(f\"h_of_x={h_of_x.shape}\")\n",
        "  return h_of_x.astype(np.int8)\n",
        "\n",
        "def predict_with_H_T(H_T, X):\n",
        "  res = np.zeros((len(X),len(H_T)))\n",
        "  for idx, h_dict in enumerate(H_T):\n",
        "    h_of_x = predict_with_h(h_dict, X)\n",
        "    res[:,idx] = h_dict['a_t']*h_of_x\n",
        "\n",
        "  #print(f\"res={res.shape}\")\n",
        "  summed_res = np.sum(res, axis=1)\n",
        "  #print(f\"summed_res={summed_res.shape}\")\n",
        "  final_res = np.zeros_like(summed_res).astype(np.int8)\n",
        "  final_res[summed_res > 0] = 1\n",
        "  final_res[summed_res < 0] = -1\n",
        "\n",
        "  #print(summed_res.shape)\n",
        "  return final_res\n",
        "\n",
        "def prediction_err(prediction, Y):\n",
        "  err = np.zeros_like(Y)\n",
        "  err[prediction != Y] = 1\n",
        "  #print(f\"prediction={prediction.shape}\")\n",
        "  #print(f\"err={err.shape}\")\n",
        "  err_rate = (float)(sum(err) / len(err))\n",
        "  return err_rate\n",
        "\n",
        "train_prediction = predict_with_H_T(H_T, Xtrain)\n",
        "train_err = prediction_err(train_prediction, Ytrain)\n",
        "\n",
        "test_prediction = predict_with_H_T(H_T, Xtest)\n",
        "test_err = prediction_err(test_prediction, Ytest)\n",
        "\n",
        "print(f\"train_err={train_err}, test_err={test_err}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_err=0.005129958960328317, test_err=0.008700102354145343\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}